{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Brief Description of the Competition and Its Goals\n",
    "\n",
    "In this competition, we aim to predict sales for thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Additional files include supplementary information that may be useful in building our models.\n",
    "\n",
    "Specifically, we'll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores. This will help ensure retailers have just enough of the right products at the right time, decreasing food waste related to overstocking and improving customer satisfaction.\n",
    "\n",
    "## Explanation of the Evaluation Metric (RMSLE)\n",
    "\n",
    "The evaluation metric for this competition is Root Mean Squared Logarithmic Error (RMSLE). The RMSLE is calculated as:\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + \\hat{y}_i) - \\log(1 + y_i))^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( n \\) is the total number of instances,\n",
    "- \\( \\hat{y}_i \\) is the predicted value of the target for instance \\( i \\),\n",
    "- \\( y_i \\) is the actual value of the target for instance \\( i \\), and\n",
    "- \\( \\log \\) is the natural logarithm.\n",
    "\n",
    "This metric is useful for this competition because it penalizes underestimates more than overestimates, which is important in a retail context where underestimating sales can lead to stockouts and lost revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Load the supplementary datasets\n",
    "stores_df = pd.read_csv('data/stores.csv')\n",
    "oil_df = pd.read_csv('data/oil.csv')\n",
    "holidays_events_df = pd.read_csv('data/holidays_events.csv')\n",
    "transactions_df = pd.read_csv('data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0\n",
      "Size of training data: (3000888, 6)\n",
      "\n",
      "Test Data:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n",
      "Size of test data: (28512, 5)\n",
      "\n",
      "Stores Data:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n",
      "Size of stores data: (54, 5)\n",
      "\n",
      "Oil Data:\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20\n",
      "Size of oil data: (1218, 2)\n",
      "\n",
      "Holidays and Events Data:\n",
      "         date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "Size of holidays and events data: (350, 6)\n",
      "\n",
      "Transactions Data:\n",
      "         date  store_nbr  transactions\n",
      "0  2013-01-01         25           770\n",
      "1  2013-01-02          1          2111\n",
      "2  2013-01-02          2          2358\n",
      "3  2013-01-02          3          3487\n",
      "4  2013-01-02          4          1922\n",
      "Size of transactions data: (83488, 3)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of each dataset\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "print(\"Size of training data:\", train_df.shape)\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.head())\n",
    "print(\"Size of test data:\", test_df.shape)\n",
    "\n",
    "print(\"\\nStores Data:\")\n",
    "print(stores_df.head())\n",
    "print(\"Size of stores data:\", stores_df.shape)\n",
    "\n",
    "print(\"\\nOil Data:\")\n",
    "print(oil_df.head())\n",
    "print(\"Size of oil data:\", oil_df.shape)\n",
    "\n",
    "print(\"\\nHolidays and Events Data:\")\n",
    "print(holidays_events_df.head())\n",
    "print(\"Size of holidays and events data:\", holidays_events_df.shape)\n",
    "\n",
    "print(\"\\nTransactions Data:\")\n",
    "print(transactions_df.head())\n",
    "print(\"Size of transactions data:\", transactions_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in stores data:\n",
      "store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in oil data:\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n",
      "\n",
      "Missing values in holidays and events data:\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in transactions data:\n",
      "date            0\n",
      "store_nbr       0\n",
      "transactions    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training dataset\n",
    "print(\"Missing values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the test dataset\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the stores dataset\n",
    "print(\"\\nMissing values in stores data:\")\n",
    "print(stores_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the oil dataset\n",
    "print(\"\\nMissing values in oil data:\")\n",
    "print(oil_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the holidays and events dataset\n",
    "print(\"\\nMissing values in holidays and events data:\")\n",
    "print(holidays_events_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in transactions data:\")\n",
    "print(transactions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 43 missing values in the oil data.\n",
    "\n",
    "Given that the oil dataset has 1218 rows and only 43 missing values, forward fill (propagating the last observed value forward) is a convenient technique. This method is particularly useful for time series data, as it maintains the continuity of the data and is less likely to introduce bias compared to mean or median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in oil data after forward and backward fill:\n",
      "date          0\n",
      "dcoilwtico    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Forward Fill: Replace missing values with the last observed value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].ffill()\n",
    "\n",
    "# Backward Fill: Replace any remaining missing values with the next observed value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].bfill()\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"Missing values in oil data after forward and backward fill:\")\n",
    "print(oil_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in training data:\n",
      "id               int64\n",
      "date            object\n",
      "store_nbr        int64\n",
      "family          object\n",
      "sales          float64\n",
      "onpromotion      int64\n",
      "dtype: object\n",
      "\n",
      "Data types in test data:\n",
      "id              int64\n",
      "date           object\n",
      "store_nbr       int64\n",
      "family         object\n",
      "onpromotion     int64\n",
      "dtype: object\n",
      "\n",
      "Data types in oil data:\n",
      "date           object\n",
      "dcoilwtico    float64\n",
      "dtype: object\n",
      "\n",
      "Data types in holidays and events data:\n",
      "date           object\n",
      "type           object\n",
      "locale         object\n",
      "locale_name    object\n",
      "description    object\n",
      "transferred      bool\n",
      "dtype: object\n",
      "\n",
      "Data types in transactions data:\n",
      "date            object\n",
      "store_nbr        int64\n",
      "transactions     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify the data types\n",
    "print(\"Data types in training data:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in test data:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in oil data:\")\n",
    "print(oil_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in holidays and events data:\")\n",
    "print(holidays_events_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in transactions data:\")\n",
    "print(transactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in training data:\n",
      "id                      int64\n",
      "date           datetime64[ns]\n",
      "store_nbr               int64\n",
      "family                 object\n",
      "sales                 float64\n",
      "onpromotion             int64\n",
      "dtype: object\n",
      "\n",
      "Data types in test data:\n",
      "id                      int64\n",
      "date           datetime64[ns]\n",
      "store_nbr               int64\n",
      "family                 object\n",
      "onpromotion             int64\n",
      "dtype: object\n",
      "\n",
      "Data types in oil data:\n",
      "date          datetime64[ns]\n",
      "dcoilwtico           float64\n",
      "dtype: object\n",
      "\n",
      "Data types in holidays and events data:\n",
      "date           datetime64[ns]\n",
      "type                   object\n",
      "locale                 object\n",
      "locale_name            object\n",
      "description            object\n",
      "transferred              bool\n",
      "dtype: object\n",
      "\n",
      "Data types in transactions data:\n",
      "date            datetime64[ns]\n",
      "store_nbr                int64\n",
      "transactions             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "holidays_events_df['date'] = pd.to_datetime(holidays_events_df['date'])\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "\n",
    "# Verify the data types\n",
    "print(\"Data types in training data:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in test data:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in oil data:\")\n",
    "print(oil_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in holidays and events data:\")\n",
    "print(holidays_events_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in transactions data:\")\n",
    "print(transactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potentially merge datasets to manage data more easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Handle missing values.\n",
    "Convert data types if necessary.\n",
    "Merge supplementary datasets with the main training and test datasets.\n",
    "Feature extraction (e.g., extracting date components)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Perform exploratory data analysis using visualizations to understand the data distribution and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Create new features from existing ones to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Train machine learning models using scikit-learn and other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate the trained models using appropriate metrics and validation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "Prepare the model for deployment, including saving the model and creating an API for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
