{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Brief Description of the Competition and Its Goals\n",
    "\n",
    "In this competition, we aim to predict sales for thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Additional files include supplementary information that may be useful in building our models.\n",
    "\n",
    "Specifically, we'll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores. This will help ensure retailers have just enough of the right products at the right time, decreasing food waste related to overstocking and improving customer satisfaction.\n",
    "\n",
    "## Explanation of the Evaluation Metric (RMSLE)\n",
    "\n",
    "The evaluation metric for this competition is Root Mean Squared Logarithmic Error (RMSLE). The RMSLE is calculated as:\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + \\hat{y}_i) - \\log(1 + y_i))^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( n \\) is the total number of instances,\n",
    "- \\( \\hat{y}_i \\) is the predicted value of the target for instance \\( i \\),\n",
    "- \\( y_i \\) is the actual value of the target for instance \\( i \\), and\n",
    "- \\( \\log \\) is the natural logarithm.\n",
    "\n",
    "This metric is useful for this competition because it penalizes underestimates more than overestimates, which is important in a retail context where underestimating sales can lead to stockouts and lost revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Load the supplementary datasets\n",
    "stores_df = pd.read_csv('data/stores.csv')\n",
    "oil_df = pd.read_csv('data/oil.csv')\n",
    "holidays_events_df = pd.read_csv('data/holidays_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0\n",
      "Size of training data: (3000888, 6)\n",
      "\n",
      "Test Data:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n",
      "Size of test data: (28512, 5)\n",
      "\n",
      "Stores Data:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n",
      "Size of stores data: (54, 5)\n",
      "\n",
      "Oil Data:\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20\n",
      "Size of oil data: (1218, 2)\n",
      "\n",
      "Holidays and Events Data:\n",
      "         date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "Size of holidays and events data: (350, 6)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of each dataset\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "print(\"Size of training data:\", train_df.shape)\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.head())\n",
    "print(\"Size of test data:\", test_df.shape)\n",
    "\n",
    "print(\"\\nStores Data:\")\n",
    "print(stores_df.head())\n",
    "print(\"Size of stores data:\", stores_df.shape)\n",
    "\n",
    "print(\"\\nOil Data:\")\n",
    "print(oil_df.head())\n",
    "print(\"Size of oil data:\", oil_df.shape)\n",
    "\n",
    "print(\"\\nHolidays and Events Data:\")\n",
    "print(holidays_events_df.head())\n",
    "print(\"Size of holidays and events data:\", holidays_events_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in stores data:\n",
      "store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in oil data:\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n",
      "\n",
      "Missing values in holidays and events data:\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training dataset\n",
    "print(\"Missing values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the test dataset\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the stores dataset\n",
    "print(\"\\nMissing values in stores data:\")\n",
    "print(stores_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the oil dataset\n",
    "print(\"\\nMissing values in oil data:\")\n",
    "print(oil_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the holidays and events dataset\n",
    "print(\"\\nMissing values in holidays and events data:\")\n",
    "print(holidays_events_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 43 missing values in the oil data.\n",
    "\n",
    "Given that the oil dataset has 1218 rows and only 43 missing values, forward fill (propagating the last observed value forward) is a convenient technique. This method is particularly useful for time series data, as it maintains the continuity of the data and is less likely to introduce bias compared to mean or median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in oil data after forward fill:\n",
      "date          0\n",
      "dcoilwtico    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nacho\\AppData\\Local\\Temp\\ipykernel_712\\1324155063.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  oil_df['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\nacho\\AppData\\Local\\Temp\\ipykernel_712\\1324155063.py:2: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  oil_df['dcoilwtico'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Forward Fill: Replace missing values with the last observed value\n",
    "oil_df['dcoilwtico'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"Missing values in oil data after forward fill:\")\n",
    "print(oil_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "Perform exploratory data analysis using visualizations to understand the data distribution and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Create new features from existing ones to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Train machine learning models using scikit-learn and other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate the trained models using appropriate metrics and validation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "Prepare the model for deployment, including saving the model and creating an API for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
