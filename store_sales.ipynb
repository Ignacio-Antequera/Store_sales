{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "## Brief Description of the Competition and Its Goals\n",
    "\n",
    "In this competition, we aim to predict sales for thousands of product families sold at Favorita stores located in Ecuador. The training data includes dates, store and product information, whether that item was being promoted, as well as the sales numbers. Additional files include supplementary information that may be useful in building our models.\n",
    "\n",
    "Specifically, we'll build a model that more accurately predicts the unit sales for thousands of items sold at different Favorita stores. This will help ensure retailers have just enough of the right products at the right time, decreasing food waste related to overstocking and improving customer satisfaction.\n",
    "\n",
    "## Explanation of the Evaluation Metric (RMSLE)\n",
    "\n",
    "The evaluation metric for this competition is Root Mean Squared Logarithmic Error (RMSLE). The RMSLE is calculated as:\n",
    "\n",
    "$$\n",
    "RMSLE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (\\log(1 + \\hat{y}_i) - \\log(1 + y_i))^2}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( n \\) is the total number of instances,\n",
    "- \\( \\hat{y}_i \\) is the predicted value of the target for instance \\( i \\),\n",
    "- \\( y_i \\) is the actual value of the target for instance \\( i \\), and\n",
    "- \\( \\log \\) is the natural logarithm.\n",
    "\n",
    "This metric is useful for this competition because it penalizes underestimates more than overestimates, which is important in a retail context where underestimating sales can lead to stockouts and lost revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Load the supplementary datasets\n",
    "stores_df = pd.read_csv('data/stores.csv')\n",
    "oil_df = pd.read_csv('data/oil.csv')\n",
    "holidays_events_df = pd.read_csv('data/holidays_events.csv')\n",
    "transactions_df = pd.read_csv('data/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "   id        date  store_nbr      family  sales  onpromotion\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4  2013-01-01          1       BOOKS    0.0            0\n",
      "Size of training data: (3000888, 6)\n",
      "\n",
      "Test Data:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n",
      "Size of test data: (28512, 5)\n",
      "\n",
      "Stores Data:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4\n",
      "Size of stores data: (54, 5)\n",
      "\n",
      "Oil Data:\n",
      "         date  dcoilwtico\n",
      "0  2013-01-01         NaN\n",
      "1  2013-01-02       93.14\n",
      "2  2013-01-03       92.97\n",
      "3  2013-01-04       93.12\n",
      "4  2013-01-07       93.20\n",
      "Size of oil data: (1218, 2)\n",
      "\n",
      "Holidays and Events Data:\n",
      "         date     type    locale locale_name                    description  \\\n",
      "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "Size of holidays and events data: (350, 6)\n",
      "\n",
      "Transactions Data:\n",
      "         date  store_nbr  transactions\n",
      "0  2013-01-01         25           770\n",
      "1  2013-01-02          1          2111\n",
      "2  2013-01-02          2          2358\n",
      "3  2013-01-02          3          3487\n",
      "4  2013-01-02          4          1922\n",
      "Size of transactions data: (83488, 3)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of each dataset\n",
    "print(\"Training Data:\")\n",
    "print(train_df.head())\n",
    "print(\"Size of training data:\", train_df.shape)\n",
    "\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_df.head())\n",
    "print(\"Size of test data:\", test_df.shape)\n",
    "\n",
    "print(\"\\nStores Data:\")\n",
    "print(stores_df.head())\n",
    "print(\"Size of stores data:\", stores_df.shape)\n",
    "\n",
    "print(\"\\nOil Data:\")\n",
    "print(oil_df.head())\n",
    "print(\"Size of oil data:\", oil_df.shape)\n",
    "\n",
    "print(\"\\nHolidays and Events Data:\")\n",
    "print(holidays_events_df.head())\n",
    "print(\"Size of holidays and events data:\", holidays_events_df.shape)\n",
    "\n",
    "print(\"\\nTransactions Data:\")\n",
    "print(transactions_df.head())\n",
    "print(\"Size of transactions data:\", transactions_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test data:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in stores data:\n",
      "store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in oil data:\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n",
      "\n",
      "Missing values in holidays and events data:\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in transactions data:\n",
      "date            0\n",
      "store_nbr       0\n",
      "transactions    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the training dataset\n",
    "print(\"Missing values in training data:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the test dataset\n",
    "print(\"\\nMissing values in test data:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the stores dataset\n",
    "print(\"\\nMissing values in stores data:\")\n",
    "print(stores_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the oil dataset\n",
    "print(\"\\nMissing values in oil data:\")\n",
    "print(oil_df.isnull().sum())\n",
    "\n",
    "# Check for missing values in the holidays and events dataset\n",
    "print(\"\\nMissing values in holidays and events data:\")\n",
    "print(holidays_events_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in transactions data:\")\n",
    "print(transactions_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have 43 missing values in the oil data.\n",
    "\n",
    "Given that the oil dataset has 1218 rows and only 43 missing values, forward fill (propagating the last observed value forward) is a convenient technique. This method is particularly useful for time series data, as it maintains the continuity of the data and is less likely to introduce bias compared to mean or median imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in oil data after forward and backward fill:\n",
      "date          0\n",
      "dcoilwtico    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Forward Fill: Replace missing values with the last observed value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].ffill()\n",
    "\n",
    "# Backward Fill: Replace any remaining missing values with the next observed value\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].bfill()\n",
    "\n",
    "# Verify that there are no missing values left\n",
    "print(\"Missing values in oil data after forward and backward fill:\")\n",
    "print(oil_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in training data:\n",
      "id               int64\n",
      "date            object\n",
      "store_nbr        int64\n",
      "family          object\n",
      "sales          float64\n",
      "onpromotion      int64\n",
      "dtype: object\n",
      "\n",
      "Data types in test data:\n",
      "id              int64\n",
      "date           object\n",
      "store_nbr       int64\n",
      "family         object\n",
      "onpromotion     int64\n",
      "dtype: object\n",
      "\n",
      "Data types in oil data:\n",
      "date           object\n",
      "dcoilwtico    float64\n",
      "dtype: object\n",
      "\n",
      "Data types in holidays and events data:\n",
      "date           object\n",
      "type           object\n",
      "locale         object\n",
      "locale_name    object\n",
      "description    object\n",
      "transferred      bool\n",
      "dtype: object\n",
      "\n",
      "Data types in transactions data:\n",
      "date            object\n",
      "store_nbr        int64\n",
      "transactions     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify the data types\n",
    "print(\"Data types in training data:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in test data:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in oil data:\")\n",
    "print(oil_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in holidays and events data:\")\n",
    "print(holidays_events_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in transactions data:\")\n",
    "print(transactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types in training data:\n",
      "id                      int64\n",
      "date           datetime64[ns]\n",
      "store_nbr               int64\n",
      "family                 object\n",
      "sales                 float64\n",
      "onpromotion             int64\n",
      "dtype: object\n",
      "\n",
      "Data types in test data:\n",
      "id                      int64\n",
      "date           datetime64[ns]\n",
      "store_nbr               int64\n",
      "family                 object\n",
      "onpromotion             int64\n",
      "dtype: object\n",
      "\n",
      "Data types in oil data:\n",
      "date          datetime64[ns]\n",
      "dcoilwtico           float64\n",
      "dtype: object\n",
      "\n",
      "Data types in holidays and events data:\n",
      "date           datetime64[ns]\n",
      "type                   object\n",
      "locale                 object\n",
      "locale_name            object\n",
      "description            object\n",
      "transferred              bool\n",
      "dtype: object\n",
      "\n",
      "Data types in transactions data:\n",
      "date            datetime64[ns]\n",
      "store_nbr                int64\n",
      "transactions             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "holidays_events_df['date'] = pd.to_datetime(holidays_events_df['date'])\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])\n",
    "\n",
    "# Verify the data types\n",
    "print(\"Data types in training data:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in test data:\")\n",
    "print(test_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in oil data:\")\n",
    "print(oil_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in holidays and events data:\")\n",
    "print(holidays_events_df.dtypes)\n",
    "\n",
    "print(\"\\nData types in transactions data:\")\n",
    "print(transactions_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the training data with the supplementary datasets\n",
    "\n",
    "# Merge with stores data\n",
    "train_df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "test_df = test_df.merge(stores_df, on='store_nbr', how='left')\n",
    "\n",
    "# Merge with oil data\n",
    "train_df = train_df.merge(oil_df, on='date', how='left')\n",
    "test_df = test_df.merge(oil_df, on='date', how='left')\n",
    "\n",
    "# Merge with holidays and events data\n",
    "train_df = train_df.merge(holidays_events_df, on='date', how='left')\n",
    "test_df = test_df.merge(holidays_events_df, on='date', how='left')\n",
    "\n",
    "# Merge with transactions data\n",
    "train_df = train_df.merge(transactions_df, on=['date', 'store_nbr'], how='left')\n",
    "test_df = test_df.merge(transactions_df, on=['date', 'store_nbr'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Training Data:\n",
      "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  dcoilwtico   type_y    locale locale_name  \\\n",
      "0      D       13       93.14  Holiday  National     Ecuador   \n",
      "1      D       13       93.14  Holiday  National     Ecuador   \n",
      "2      D       13       93.14  Holiday  National     Ecuador   \n",
      "3      D       13       93.14  Holiday  National     Ecuador   \n",
      "4      D       13       93.14  Holiday  National     Ecuador   \n",
      "\n",
      "          description transferred  transactions  \n",
      "0  Primer dia del ano       False           NaN  \n",
      "1  Primer dia del ano       False           NaN  \n",
      "2  Primer dia del ano       False           NaN  \n",
      "3  Primer dia del ano       False           NaN  \n",
      "4  Primer dia del ano       False           NaN  \n",
      "Size of merged training data: (3054348, 17)\n",
      "Merged Test Data:\n",
      "        id       date  store_nbr      family  onpromotion   city      state  \\\n",
      "0  3000888 2017-08-16          1  AUTOMOTIVE            0  Quito  Pichincha   \n",
      "1  3000889 2017-08-16          1   BABY CARE            0  Quito  Pichincha   \n",
      "2  3000890 2017-08-16          1      BEAUTY            2  Quito  Pichincha   \n",
      "3  3000891 2017-08-16          1   BEVERAGES           20  Quito  Pichincha   \n",
      "4  3000892 2017-08-16          1       BOOKS            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  dcoilwtico type_y locale locale_name description  \\\n",
      "0      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "1      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "2      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "3      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "4      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "\n",
      "  transferred  transactions  \n",
      "0         NaN           NaN  \n",
      "1         NaN           NaN  \n",
      "2         NaN           NaN  \n",
      "3         NaN           NaN  \n",
      "4         NaN           NaN  \n",
      "Size of merged test data: (28512, 16)\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the merged training data\n",
    "print(\"Merged Training Data:\")\n",
    "print(train_df.head())\n",
    "print(\"Size of merged training data:\", train_df.shape)\n",
    "\n",
    "# Display the first few rows of the merged test data\n",
    "print(\"Merged Test Data:\")\n",
    "print(test_df.head())\n",
    "print(\"Size of merged test data:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "The next step is to perform feature engineering to create new features that can help improve the model's performance. Here are some feature engineering steps you can take:\n",
    "\n",
    "- Extract Date Components: Extract year, month, day, and day of the week from the date column.\n",
    "- Lag Features: Create lag features for sales to capture trends and seasonality.\n",
    "- Rolling Statistics: Create rolling mean, median, and standard deviation features for sales.\n",
    "- Promotion Features: Create features indicating whether a product was on promotion.\n",
    "- Holiday Features: Create features indicating whether a date is a holiday or an event.\n",
    "\n",
    "Let's start with extracting date components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data with Date Components:\n",
      "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  ...   type_y    locale locale_name         description  \\\n",
      "0      D       13  ...  Holiday  National     Ecuador  Primer dia del ano   \n",
      "1      D       13  ...  Holiday  National     Ecuador  Primer dia del ano   \n",
      "2      D       13  ...  Holiday  National     Ecuador  Primer dia del ano   \n",
      "3      D       13  ...  Holiday  National     Ecuador  Primer dia del ano   \n",
      "4      D       13  ...  Holiday  National     Ecuador  Primer dia del ano   \n",
      "\n",
      "  transferred transactions  year  month  day  day_of_week  \n",
      "0       False          NaN  2013      1    1            1  \n",
      "1       False          NaN  2013      1    1            1  \n",
      "2       False          NaN  2013      1    1            1  \n",
      "3       False          NaN  2013      1    1            1  \n",
      "4       False          NaN  2013      1    1            1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Test Data with Date Components:\n",
      "        id       date  store_nbr      family  onpromotion   city      state  \\\n",
      "0  3000888 2017-08-16          1  AUTOMOTIVE            0  Quito  Pichincha   \n",
      "1  3000889 2017-08-16          1   BABY CARE            0  Quito  Pichincha   \n",
      "2  3000890 2017-08-16          1      BEAUTY            2  Quito  Pichincha   \n",
      "3  3000891 2017-08-16          1   BEVERAGES           20  Quito  Pichincha   \n",
      "4  3000892 2017-08-16          1       BOOKS            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  dcoilwtico type_y locale locale_name description  \\\n",
      "0      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "1      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "2      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "3      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "4      D       13        46.8    NaN    NaN         NaN         NaN   \n",
      "\n",
      "  transferred  transactions  year  month  day  day_of_week  \n",
      "0         NaN           NaN  2017      8   16            2  \n",
      "1         NaN           NaN  2017      8   16            2  \n",
      "2         NaN           NaN  2017      8   16            2  \n",
      "3         NaN           NaN  2017      8   16            2  \n",
      "4         NaN           NaN  2017      8   16            2  \n"
     ]
    }
   ],
   "source": [
    "# Extract date components\n",
    "train_df['year'] = train_df['date'].dt.year\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df['day_of_week'] = train_df['date'].dt.dayofweek\n",
    "\n",
    "test_df['year'] = test_df['date'].dt.year\n",
    "test_df['month'] = test_df['date'].dt.month\n",
    "test_df['day'] = test_df['date'].dt.day\n",
    "test_df['day_of_week'] = test_df['date'].dt.dayofweek\n",
    "\n",
    "# Display the first few rows of the training data with new features\n",
    "print(\"Training Data with Date Components:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Display the first few rows of the test data with new features\n",
    "print(\"Test Data with Date Components:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create lag features for sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data with Lag Features:\n",
      "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  ...         description transferred transactions  year  \\\n",
      "0      D       13  ...  Primer dia del ano       False          NaN  2013   \n",
      "1      D       13  ...  Primer dia del ano       False          NaN  2013   \n",
      "2      D       13  ...  Primer dia del ano       False          NaN  2013   \n",
      "3      D       13  ...  Primer dia del ano       False          NaN  2013   \n",
      "4      D       13  ...  Primer dia del ano       False          NaN  2013   \n",
      "\n",
      "  month day  day_of_week  lag_1  lag_7  lag_30  \n",
      "0     1   1            1    NaN    NaN     NaN  \n",
      "1     1   1            1    NaN    NaN     NaN  \n",
      "2     1   1            1    NaN    NaN     NaN  \n",
      "3     1   1            1    NaN    NaN     NaN  \n",
      "4     1   1            1    NaN    NaN     NaN  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create lag features for sales\n",
    "train_df['lag_1'] = train_df.groupby(['store_nbr', 'family'])['sales'].shift(1)\n",
    "train_df['lag_7'] = train_df.groupby(['store_nbr', 'family'])['sales'].shift(7)\n",
    "train_df['lag_30'] = train_df.groupby(['store_nbr', 'family'])['sales'].shift(30)\n",
    "\n",
    "# Display the first few rows of the training data with lag features\n",
    "print(\"Training Data with Lag Features:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create rolling statistics for sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data with Rolling Statistics:\n",
      "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  ...  year month day day_of_week lag_1 lag_7  lag_30  \\\n",
      "0      D       13  ...  2013     1   1           1   NaN   NaN     NaN   \n",
      "1      D       13  ...  2013     1   1           1   NaN   NaN     NaN   \n",
      "2      D       13  ...  2013     1   1           1   NaN   NaN     NaN   \n",
      "3      D       13  ...  2013     1   1           1   NaN   NaN     NaN   \n",
      "4      D       13  ...  2013     1   1           1   NaN   NaN     NaN   \n",
      "\n",
      "   rolling_mean_7  rolling_median_7  rolling_std_7  \n",
      "0             NaN               NaN            NaN  \n",
      "1             NaN               NaN            NaN  \n",
      "2             NaN               NaN            NaN  \n",
      "3             NaN               NaN            NaN  \n",
      "4             NaN               NaN            NaN  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create rolling mean, median, and standard deviation features for sales\n",
    "train_df['rolling_mean_7'] = train_df.groupby(['store_nbr', 'family'])['sales'].rolling(7).mean().reset_index(level=[0,1], drop=True)\n",
    "train_df['rolling_median_7'] = train_df.groupby(['store_nbr', 'family'])['sales'].rolling(7).median().reset_index(level=[0,1], drop=True)\n",
    "train_df['rolling_std_7'] = train_df.groupby(['store_nbr', 'family'])['sales'].rolling(7).std().reset_index(level=[0,1], drop=True)\n",
    "\n",
    "# Display the first few rows of the training data with rolling statistics\n",
    "print(\"Training Data with Rolling Statistics:\")\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create promotion and holiday features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data with Promotion and Holiday Features:\n",
      "   id       date  store_nbr      family  sales  onpromotion   city      state  \\\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0  Quito  Pichincha   \n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0  Quito  Pichincha   \n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0  Quito  Pichincha   \n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0  Quito  Pichincha   \n",
      "4   4 2013-01-01          1       BOOKS    0.0            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  ...  day day_of_week lag_1 lag_7 lag_30 rolling_mean_7  \\\n",
      "0      D       13  ...    1           1   NaN   NaN    NaN            NaN   \n",
      "1      D       13  ...    1           1   NaN   NaN    NaN            NaN   \n",
      "2      D       13  ...    1           1   NaN   NaN    NaN            NaN   \n",
      "3      D       13  ...    1           1   NaN   NaN    NaN            NaN   \n",
      "4      D       13  ...    1           1   NaN   NaN    NaN            NaN   \n",
      "\n",
      "   rolling_median_7  rolling_std_7  is_promoted  is_holiday  \n",
      "0               NaN            NaN        False        True  \n",
      "1               NaN            NaN        False        True  \n",
      "2               NaN            NaN        False        True  \n",
      "3               NaN            NaN        False        True  \n",
      "4               NaN            NaN        False        True  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "Test Data with Promotion and Holiday Features:\n",
      "        id       date  store_nbr      family  onpromotion   city      state  \\\n",
      "0  3000888 2017-08-16          1  AUTOMOTIVE            0  Quito  Pichincha   \n",
      "1  3000889 2017-08-16          1   BABY CARE            0  Quito  Pichincha   \n",
      "2  3000890 2017-08-16          1      BEAUTY            2  Quito  Pichincha   \n",
      "3  3000891 2017-08-16          1   BEVERAGES           20  Quito  Pichincha   \n",
      "4  3000892 2017-08-16          1       BOOKS            0  Quito  Pichincha   \n",
      "\n",
      "  type_x  cluster  dcoilwtico  ... locale_name description transferred  \\\n",
      "0      D       13        46.8  ...         NaN         NaN         NaN   \n",
      "1      D       13        46.8  ...         NaN         NaN         NaN   \n",
      "2      D       13        46.8  ...         NaN         NaN         NaN   \n",
      "3      D       13        46.8  ...         NaN         NaN         NaN   \n",
      "4      D       13        46.8  ...         NaN         NaN         NaN   \n",
      "\n",
      "  transactions  year  month  day  day_of_week  is_promoted  is_holiday  \n",
      "0          NaN  2017      8   16            2        False       False  \n",
      "1          NaN  2017      8   16            2        False       False  \n",
      "2          NaN  2017      8   16            2         True       False  \n",
      "3          NaN  2017      8   16            2         True       False  \n",
      "4          NaN  2017      8   16            2        False       False  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create promotion features\n",
    "train_df['is_promoted'] = train_df['onpromotion'] > 0\n",
    "test_df['is_promoted'] = test_df['onpromotion'] > 0\n",
    "\n",
    "# Create holiday features\n",
    "train_df['is_holiday'] = train_df['type_y'].notnull()\n",
    "test_df['is_holiday'] = test_df['type_y'].notnull()\n",
    "\n",
    "# Display the first few rows of the training data with promotion and holiday features\n",
    "print(\"Training Data with Promotion and Holiday Features:\")\n",
    "print(train_df.head())\n",
    "\n",
    "# Display the first few rows of the test data with promotion and holiday features\n",
    "print(\"Test Data with Promotion and Holiday Features:\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "Perform exploratory data analysis using visualizations to understand the data distribution and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Train machine learning models using scikit-learn and other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "Evaluate the trained models using appropriate metrics and validation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment\n",
    "Prepare the model for deployment, including saving the model and creating an API for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
